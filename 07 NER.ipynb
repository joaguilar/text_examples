{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6771e8",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28cb7f",
   "metadata": {},
   "source": [
    "## NER Utilizando métodos tradicionales\n",
    "\n",
    "Los métodos \"tradicionales\" son más eficientes aunque pueden no ser tan efectivos como modelos de lenguaje para dominios específicos. Estos métodos usan una combinacion de POS y diccionarios para la identificación de NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3004b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar los recursos necesarios de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un conjunto de textos para analizar\n",
    "texts = [\n",
    "    \"Apple Inc. is looking to buy a startup in the United States.\",\n",
    "    \"Barack Obama was the 44th President of the United States.\",\n",
    "    \"Elon Musk founded SpaceX, an aerospace manufacturer and space transportation company.\",\n",
    "    \"The Amazon rainforest is the largest tropical rainforest in the world.\",\n",
    "    \"Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\"\n",
    "]\n",
    "\n",
    "# Crear un DataFrame\n",
    "texts_df = pd.DataFrame(texts, columns=['Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c5b49",
   "metadata": {},
   "source": [
    "En este caso se utiliza la función `ne_chunk` de `nltk` para la identificación de NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer entidades nombradas\n",
    "def extract_entities(text):\n",
    "    # Tokenizar el texto\n",
    "    words = word_tokenize(text)\n",
    "    # Etiquetado de partes del discurso\n",
    "    pos_tags = pos_tag(words)\n",
    "    # Reconocimiento de entidades nombradas\n",
    "    chunks = ne_chunk(pos_tags)\n",
    "    entities = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if isinstance(chunk, Tree):\n",
    "            entity = \" \".join([token for token, pos in chunk.leaves()])\n",
    "            entity_type = chunk.label()\n",
    "            entities.append((entity, entity_type))\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Aplicar el reconocimiento de entidades nombradas\n",
    "texts_df['Entities'] = texts_df['Text'].apply(extract_entities)\n",
    "\n",
    "\n",
    "texts_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a0ad9",
   "metadata": {},
   "source": [
    "# NER Utilizando modelos de lenguaje\n",
    "\n",
    "Este ejemplo demuestra cómo aplicar modelos de lenguaje avanzados para NER. Suelen ser más precisos a un mayor costo computacional tanto a la hora de ejecutarse y ni que decir a la hora de entrenarse.\n",
    "\n",
    "Cargamos los textos en el dataframe de nuevo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c64c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "texts_df = pd.DataFrame(texts, columns=['Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f61f56",
   "metadata": {},
   "source": [
    "Utilizamos el modelo `dbmdz/bert-large-cased-finetuned-conll03-english` obtenido de HuggingFace en [dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
    "\n",
    "Utilizamos la acceleración de la máquina, en este caso el motor mps en macOS ARM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Cargar el modelo de reconocimiento de entidades nombradas\n",
    "mps_device = \"mps\"\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\", device = mps_device)\n",
    "\n",
    "# Función para extraer entidades nombradas\n",
    "def extract_entities(text):\n",
    "    entities = ner_pipeline(text)\n",
    "    return [(entity['entity_group'], entity['word']) for entity in entities]\n",
    "\n",
    "# Aplicar el reconocimiento de entidades nombradas\n",
    "texts_df['Entities'] = texts_df['Text'].apply(extract_entities)\n",
    "\n",
    "# Mostrar los resultados\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Named Entity Recognition\", dataframe=texts_df)\n",
    "\n",
    "texts_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97607c",
   "metadata": {},
   "source": [
    "Nótese la diferencia en tiempos de ejecución entre ambos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf3187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_examples)",
   "language": "python",
   "name": "text_examples_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
